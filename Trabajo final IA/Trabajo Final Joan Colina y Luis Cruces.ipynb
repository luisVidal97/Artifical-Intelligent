{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Final \n",
    "\n",
    "_Fecha: 16 de mayo 2019_\n",
    "\n",
    "Enviar un enlace a un repositorio de GitHub que contenga los trabajos realizados durante el semestre, la carpeta debe contener las siguientes entregas:\n",
    "\n",
    "+ MNIST (digitos) con algoritmo deterministico\n",
    "+ Tic-tac-toe\n",
    "+ Sistema experto\n",
    "+ Opcional (Artificial Life)\n",
    "+ MNIST (digitos) machine learning - Kmeans\n",
    "+ MNIST (digitos) deep learning, Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST (dígitos) deep learning, Tensorflow\n",
    "\n",
    "__Integrantes:__\n",
    "\n",
    "+ Nombre: Joan David Colina.\n",
    "+ Nombre: Luis Fernando Cruces.\n",
    "\n",
    "\n",
    "Entrenar una red neuronal con el fin de detectar los dígitos de MNIST y comparar sus resultados contra el algoritmo determinístico y el modelo de machine learning kmeans.\n",
    "\n",
    "Evaluar los resultados contra dos medidas de evaluación (accuracy y tiempo de entramiento). Se recomienda realizar el hold-out con un 80% para entrenamiento y un conjunto de testeo del 20%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Read data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x):\n",
    "    weight_init = tf.random_normal_initializer()\n",
    "    bias_init = tf.constant_initializer(value=0)\n",
    "    W = tf.get_variable(\"W\", [784, 10], initializer=weight_init)\n",
    "    b = tf.get_variable(\"b\", [10], initializer=bias_init)\n",
    "    output = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(output, y):\n",
    "    dot_product = y * tf.log(output)    \n",
    "    xentropy = -tf.reduce_sum(dot_product, reduction_indices=1)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(output, y):\n",
    "    correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(cost, global_step):\n",
    "    tf.summary.scalar(\"cost\", cost)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    train_op = optimizer.minimize(cost, global_step=global_step)\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_epochs = 300\n",
    "batch_size = 100\n",
    "display_step = 5\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    # mnist data image of shape 28*28=784\n",
    "    x = tf.placeholder(tf.float32, [None, 784])    \n",
    "    # 0-9 digits recognition => 10 classes\n",
    "    y = tf.placeholder(tf.float32, [None, 10])    \n",
    "    output = inference(x)    \n",
    "    cost = loss(output, y) \n",
    "    \n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)    \n",
    "    train_op = training(cost, global_step)    \n",
    "    eval_op = evaluate(output, y)\n",
    "    \n",
    "    summary_op = tf.summary.merge_all()    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    sess = tf.Session()    \n",
    "    summary_writer = tf.summary.FileWriter(\"logistic_logs/\", graph=sess.graph)\n",
    "    \n",
    "    init_op = tf.global_variables_initializer()    \n",
    "    sess.run(init_op)\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            mbatch_x, mbatch_y = mnist.train.next_batch(batch_size)\n",
    "            # Fit training using batch data\n",
    "            feed_dict = {x : mbatch_x, y : mbatch_y}\n",
    "            sess.run(train_op, feed_dict=feed_dict)\n",
    "            # Compute average loss\n",
    "            minibatch_cost = sess.run(cost, feed_dict=feed_dict)\n",
    "            avg_cost += minibatch_cost/total_batch\n",
    "            \n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            val_feed_dict = {\n",
    "                x : mnist.validation.images,\n",
    "                y : mnist.validation.labels\n",
    "            }\n",
    "            accuracy = sess.run(eval_op, feed_dict=val_feed_dict)\n",
    "            print (\"Validation Error:\", (1 - accuracy))\n",
    "            summary_str = sess.run(summary_op, feed_dict=feed_dict)\n",
    "            summary_writer.add_summary(summary_str, sess.run(global_step))\n",
    "            \n",
    "            saver.save(sess, \"logistic_logs/model-checkpoint\", global_step=global_step)\n",
    "            \n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    test_feed_dict = {\n",
    "        x : mnist.test.images,\n",
    "        y : mnist.test.labels\n",
    "    }\n",
    "    accuracy = sess.run(eval_op, feed_dict=test_feed_dict)\n",
    "    print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Resultados del algoritmo #3:\n",
    "\n",
    "Validation Error: 0.19760000705718994\n",
    "Validation Error: 0.14899998903274536\n",
    "Validation Error: 0.13859999179840088\n",
    "Validation Error: 0.1305999755859375\n",
    "Validation Error: 0.1258000135421753\n",
    "Validation Error: 0.12360000610351562\n",
    "Validation Error: 0.12159997224807739\n",
    "Validation Error: 0.12040001153945923\n",
    "Validation Error: 0.12000000476837158\n",
    "Validation Error: 0.11860001087188721\n",
    "Validation Error: 0.11879998445510864\n",
    "Validation Error: 0.118399977684021\n",
    "Validation Error: 0.118399977684021\n",
    "Validation Error: 0.11760002374649048\n",
    "Validation Error: 0.11760002374649048\n",
    "Validation Error: 0.11760002374649048\n",
    "Validation Error: 0.11680001020431519\n",
    "Validation Error: 0.11720001697540283\n",
    "Validation Error: 0.11580002307891846\n",
    "Validation Error: 0.11619997024536133\n",
    "Validation Error: 0.11599999666213989\n",
    "Validation Error: 0.11559998989105225\n",
    "Validation Error: 0.11619997024536133\n",
    "Validation Error: 0.02240002155303955\n",
    "Validation Error: 0.02319997549057007\n",
    "Validation Error: 0.021799981594085693\n",
    "Validation Error: 0.021399974822998047\n",
    "Validation Error: 0.02240002155303955\n",
    "Validation Error: 0.021399974822998047\n",
    "Validation Error: 0.020799994468688965\n",
    "Validation Error: 0.021399974822998047\n",
    "Validation Error: 0.021399974822998047\n",
    "Validation Error: 0.019599974155426025\n",
    "Validation Error: 0.021399974822998047\n",
    "Validation Error: 0.020200014114379883\n",
    "Validation Error: 0.02060002088546753\n",
    "Validation Error: 0.019599974155426025\n",
    "Validation Error: 0.019599974155426025\n",
    "Validation Error: 0.019999980926513672\n",
    "Validation Error: 0.019999980926513672\n",
    "Validation Error: 0.019800007343292236\n",
    "Validation Error: 0.019999980926513672\n",
    "Validation Error: 0.02039998769760132\n",
    "Validation Error: 0.020799994468688965\n",
    "Validation Error: 0.02039998769760132\n",
    "Validation Error: 0.02039998769760132\n",
    "Validation Error: 0.02060002088546753\n",
    "Validation Error: 0.019999980926513672\n",
    "Validation Error: 0.019999980926513672\n",
    "Validation Error: 0.02039998769760132\n",
    "Validation Error: 0.019800007343292236\n",
    "Validation Error: 0.020200014114379883\n",
    "Validation Error: 0.02060002088546753\n",
    "Validation Error: 0.020200014114379883\n",
    "Validation Error: 0.020200014114379883\n",
    "Validation Error: 0.019999980926513672\n",
    "Validation Error: 0.020799994468688965\n",
    "Validation Error: 0.019999980926513672\n",
    "Validation Error: 0.02039998769760132\n",
    "Validation Error: 0.02039998769760132\n",
    "Optimization Finished!\n",
    "Test Accuracy: 0.9806"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación contra el mejor modelo KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reales   : [3 4 5 6 7 8 9 0 9 5 5 6 5 0 9 8 9 8 4 1 7 7 3 5 1]\n",
      "Estimados: [3 4 5 6 7 8 9 0 9 5 5 6 5 0 9 8 9 8 4 1 7 7 3 5 1]\n",
      "KNN promedio:  0.9637883008356546\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import sklearn.metrics as metrics\n",
    "import pylab as pl\n",
    "import math\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "digits = load_digits()\n",
    "percentFit = 0.8\n",
    "numImagenes= len(digits.images)\n",
    "\n",
    "timeKNN = 0.0\n",
    "\n",
    "trainingLimit = math.floor(numImagenes*percentFit)+1\n",
    "limit = math.ceil(numImagenes*percentFit)\n",
    "\n",
    "\n",
    "targetTraining = digits.target[0:trainingLimit]\n",
    "targeTest = digits.target[limit:]\n",
    "\n",
    "imagesTraining = digits.images[0 : trainingLimit].reshape((len(targetTraining),-1))\n",
    "imagesTest = digits.images[limit : ].reshape((len(targeTest),-1))\n",
    "\n",
    "\n",
    "knn= KNeighborsClassifier()\n",
    "\n",
    "\n",
    "\n",
    "fit = knn.fit(imagesTraining,targetTraining)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "targetTest_estimado= fit.predict(imagesTest)\n",
    "print(\"Reales   :\", targeTest[0:25])\n",
    "print(\"Estimados:\", targetTest_estimado[0:25])\n",
    "\n",
    "\n",
    "knn_accuracy = metrics.accuracy_score(targeTest, targetTest_estimado)\n",
    "print(\"KNN promedio: \", knn_accuracy)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación contra el resultado del algoritmo deterministico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se tienen en total: 1797 imágenes\n",
      "Imagenes totales:\n",
      "351\n",
      "Imagenes totales del 2:  177\n",
      "acertadas:  41\n",
      "correctitud:  23.163841807909606 %\n",
      "Imagenes totales del 8:  174\n",
      "correctitud:  14.367816091954023 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_digits\n",
    "import pylab as pl\n",
    "\n",
    "#Representación de la matriz\n",
    "matriz = []\n",
    "#Representación de la lista que me va contener los números 2 y 8\n",
    "etiquetas = []\n",
    "\n",
    "digits = load_digits()\n",
    "pl.gray() # Queremos las imágenes en grises\n",
    "\n",
    "numImagenes = len(digits.images) # Numero de imagenes, len es un método que provee el tamaño del arreglo\n",
    "print(\"Se tienen en total:\", numImagenes, \"imágenes\")\n",
    "\n",
    "y = digits.target # el método nos provee las etiquetas de las imágenes en un arreglo\n",
    "\n",
    "#define las variables  que van a contener el total de numeros 2 y 8 que hay en las matrices\n",
    "count2=0\n",
    "count8=0\n",
    "for d in range(0,len(y)):\n",
    "        if(y[d]==2):\n",
    "            count2+=1\n",
    "        else:\n",
    "            count8+=1\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "#se introduce las matrices a la variable matriz y, además, rellena la lista etiquetas\n",
    "# con la cantidad total de 2 y 8\n",
    "#------------------------------------------------------------------------------------------\n",
    "for i in range(0,len(y)):\n",
    "    matriz.append(digits.images[i])\n",
    "    if (2 == y[i]) | (8 == y[i]):\n",
    "        etiquetas.append(y[i])\n",
    "                \n",
    "#------------------------------------------------------------------------------------------\n",
    "#Caso que verifica si, dada una matriz, corresponde al numero 2\n",
    "#------------------------------------------------------------------------------------------            \n",
    "def casoNumero2(mati):\n",
    "    count =0\n",
    "    flag = False\n",
    "    for i in range(0,8):\n",
    "        for j in range(2,6):\n",
    "            if(mati[i,j]>0 & i!=6):\n",
    "                count+=1\n",
    "            \n",
    "    count2=0\n",
    "    for m in range(1,7):\n",
    "        if(mati[i,j]>0 ):\n",
    "            count2 +=1\n",
    "        \n",
    "    if(count>=20 &count<23 &count2>4): \n",
    "        flag=True\n",
    "    else:\n",
    "        flag = False\n",
    "    return flag\n",
    "            \n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "#Método que se encarga de hacer todas las sumas de los pixeles del numero 8 para luego sacar el promedio en el metodo siguiente\n",
    "#------------------------------------------------------------------------------------------ \n",
    "def matrizpromedio(meti,list,num):\n",
    "            \n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            meti[i][j]+=list[i,j]\n",
    "            \n",
    "    return meti\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "#Método  que se encarga de sacar la matriz promedio para el número 8\n",
    "#------------------------------------------------------------------------------------------ \n",
    "def meraLabia(numer):\n",
    "    meta = [[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],\n",
    "              [0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0]]\n",
    "    for g in range(0,len(digits.images)):\n",
    "         meta= matrizpromedio( meta, digits.images[g],count8)\n",
    "        \n",
    "    \n",
    "    for n in range(0,7):\n",
    "        for m in range(0,7):\n",
    "            meta[n][m]=(meta[n][m]/count8)\n",
    "    \n",
    "    return meta\n",
    "    \n",
    "#------------------------------------------------------------------------------------------\n",
    "#Método qpara el número 8 que compara  la matriz promedio del número 8 con cualquier otra matriz\n",
    "#------------------------------------------------------------------------------------------     \n",
    "def comparar(promedio, otra):\n",
    "    flag=False\n",
    "    contador=0\n",
    "    for h in range(1,7):\n",
    "        for j in range(1,7):  \n",
    "            #print(otra[h][j],\" esta \",promedio[h][j]) \n",
    "            if(otra[h][j]>=promedio[h][j]):\n",
    "                contador+=1\n",
    "              \n",
    "    if(contador>23):\n",
    "        flag=True\n",
    "    return flag\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "#Método en el cual se le pasa la matriz para que evalue la cantidad de aciertos para cada número\n",
    "#------------------------------------------------------------------------------------------ \n",
    "def respuesta(list,label):\n",
    "    totalImagenes = len(list)\n",
    "    acertadas2 = 0\n",
    "    acertadas8 = 0\n",
    "    \n",
    "    counta2=0\n",
    "    counta8=0\n",
    "    for d in range(0,len(label)):\n",
    "        if(label[d]==2):\n",
    "            counta2+=1\n",
    "        else:\n",
    "            counta8+=1\n",
    "    \n",
    "    for i in range (0,len(list)):\n",
    "        if(casoNumero2(list[i])):\n",
    "            acertadas2+=1\n",
    "        if(comparar(meraLabia(counta8), list[i])):\n",
    "            acertadas8+=1\n",
    "            \n",
    "    print(\"Imagenes totales:\")\n",
    "    print(len(label))\n",
    "    print(\"Imagenes totales del 2: \",count2)\n",
    "    print(\"acertadas: \",acertadas2)\n",
    "    print(\"correctitud: \",(acertadas2/count2)*100, \"%\")\n",
    "    print(\"Imagenes totales del 8: \",counta8)\n",
    "    print(\"correctitud: \",(acertadas8/counta8)*100, \"%\")\n",
    "    \n",
    "respuesta(matriz,etiquetas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "A la hora de enfrentarnos al problema de reconocimientos de números, podemos hacerlo mediante diferentes maneras. Aquí se presentaron 3 diferentes métodos con sus resultados. Como se pudo observar, a la hora de  usar el algoritmo deterministicos de la programación tradicional obtuvimos un resultado muy pobre con un porcentaje de correctitud para ambos números: 2 y 8. Cuando nos enfocamos en los dos métodos  que usan inteligencia artifical, nos damos cuenta que cuentan con un mayor número de correctitud. En este caso, se obtienen mejores  resultados con el uso de redes neuronales  que con el modelo KNN, sin embargo,  se demora mas o toma más tiempo entrenar el algoritmo de redes neur\n",
    "\n",
    "\n",
    "\n",
    "Para el problema de determininar que digito es el que esta representado en una matriz, podemos emplear distintos metodos. Nosotros en el transcurso de el laboratorio, realizamos y analizamos diferentes modelos para enfrentar este problema. Cuando usamos un algoritmo deterministico de la programacion tradicional obtenemos un resultado de 66.11% en promedio al querer predecir matrices que representaban el numero 2 y 8. Obtuvimos un resultado de 96.65% usando el modelo de KNN y 97.64% usando una red neuronal. Como se puede evidenciar los resultados obtenidos empleando un modelo basado en inteligencia artificial son mucho mas precisos realizando la predicción.\n",
    "El algoritmo deterministico empleado para predecir que numero representa una matriz, posee una precision muy inferior a los otros dos modelos comparados, dado que lo que hace es comparar una nueva entrada con una matriz promediada que usa como referencia. La debilidad radica en que hay diferentes maneras de representar un numero en una matriz y no todos siguen el mismo esquema que posee la matriz de referencia, lo que produce resultados inferiores.\n",
    "El modelo de KNN resulta muy preciso dado que una vez entrenado el modelo y entra un dato nuevo que se quiere predecir, el modelo compara con los datos que ya posee verificando que datos se acercan mas la nueva entrada es decir el modelo compara la entrada con los \"vecinos mas cercanos\" para clasificar la nueva entrada. De esta forma puede predecir con base en lo que ya \"conoce\". \n",
    "El modelo de la red neuronal resulta un poco mas preciso que el modelo KNN dado que es un modelo mas potente. Esto debido a que la union de muchas neuronas pueden modelar y clasificar informacion de forma mas precisa y completa. Cada neurona es una unidad de clasificacion que usa una regresion lineal combinado con una funcion de activacion que permite realizar deformaciones no lineales, esto permite encadenar varias neuronas evitando obtener siempre un resultado lineal. Esto aunado a el uso del algoritmo de Backpropagation que usa el concepto de gradiente para irse ajustando y en cada iteracion mejorar los resultados de la red disminiyendo los errores. Lo anteriormente mencionado hacen de las redes neuronales un modelo mucho mas robusto y capaz de clasificar y tomar desiciones.\n",
    "TIME:\n",
    "el tiempo de entrenamiento de cada algoritmo es diferente, debido a que cada uno utiliza una estrategia distinta para su entrenamiento. Por el lado del algoritmo determinístico, su entrenamiento consiste en crear una matriz promedio para todos los datos de entrenamiento dados de un número, donde su tiempo es de 79.7 ms, solamente para matrices correspondientes a los numeros 2 y 8.\n",
    "Por otro lado, el algoritmo de KNN cuenta con un mecanismo distinto de entrenamiento. Éste consiste en que ubica a los elementos de entrenamiento según los valores de los atributos que se tienen en cuenta para la clasificación. Donde para realizar la predicción, no se ha creado un modelo previamente, si no que se utiliza cada uno de los elementos para clasificar el objeto de estudio. Esta es una de las razones por la que es considerado un algoritmo con un costo considerable para procesamiento. El algoritmo tuvo un tiempo de entrenamiento de 31.3 ms para un 80% de los datos totales usados.\n",
    "Por último, la red neuronal \"perceptrón\" es el algoritmo que más tiempo tomó para su entrenamiento. Esto debido a que, su entrenamiento consiste en ir variando los pesos que se le otorga a cada entrada para que el error de precisión sea el minimo. Este proceso se realiza iterativamente, teniendo en cuenta los diferentes pesos de cada atributo. Para el 80% de los datos utilizados en entrenamiento, el algoritmo tardó cerca de 27 min 53 s.\n",
    "Los anteriores tiempos pueden variar debido a factores como la CPU. Comparando el algoritmo KNN con el de redes neuronales que tuvieron una precisión de más del 95%, el tiempo de las redes neuronales es mucho mayor. Sin embargo, la red neuronal es un método que tiene un uso más amplio y preciso que el de KNN, así que la utilización de cada uno ya dependerá de factores como: la naturaleza del problema, recursos computacionales disponibles y la cantidad de los datos\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
